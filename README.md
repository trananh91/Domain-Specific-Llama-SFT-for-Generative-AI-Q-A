# Domain Specific Llama SFT for Generative AI Q&A.
# (AWS ASEAN LLM League 2025) - Updating...

## About this Project
This project, "Domain-Specific Llama SFT for Generative AI Q&A," was developed following my participation in the AWS ASEAN LLM League 2025, an enriching experience hosted by AI Singapore and AWS for the ASEAN regions.

The core objective of this initiative is to demonstrate the effectiveness of Supervised Fine-Tuning (SFT) on a Llama model to create a highly specialized generative AI Q&A system for a specific domain.  
The competition leverages AWS services for model fine-tuning process.  
In this project, I use the capabilities of Nebius AI instead.

---

## Project Structure & Workflow
This project is organized into distinct phases, each with its dedicated documentation:

* **Initial Research:** Understanding the problem space and laying the groundwork.
* **Data Preparation:** Curating and processing the domain-specific dataset.
* **Model Fine-Tuning:** The core process of adapting the Llama model.
* **Evaluation:** Assessing the performance of the fine-tuned model.

---

## Detailed Documented Sections
For in-depth information on each phase, please refer to the dedicated documentation files:

* **Initial Research:** [Read more](./research/initial_research.md)
* **Data Preparation:** [Read more](./data_prep/data_preparation.md)
* **Model Fine-Tuning:** [Read more](./model_ft/model_fine_tuning.md)
* **Evaluation:** [Read more](./eval/evaluation.md)

## Future work

## Acknowledgments