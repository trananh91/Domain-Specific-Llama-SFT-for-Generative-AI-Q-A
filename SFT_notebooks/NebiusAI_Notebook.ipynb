{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCJAFNEzF4Vl"
      },
      "source": [
        "## Initialize OpenAI Client\n",
        "Set up the OpenAI client with Nebius AI's API endpoint and your API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t9lE90uSDllW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv-WrbiMFtuL"
      },
      "source": [
        "## Upload Training and Validation Datasets\n",
        "Nebius AI requires datasets in `.jsonl` format. Upload your training and validation datasets. In my case, I have prepared only one jsonl file, so that I will use a short script to split that file into two new files for training and validation, with the ratio of 9:1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset saved to data/train_dataset.jsonl\n",
            "Validation dataset saved to data/valid_dataset.jsonl\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "input_file = r\"data/dataset.jsonl\"\n",
        "train_file = r\"data/train_dataset.jsonl\"\n",
        "valid_file = r\"data/valid_dataset.jsonl\"\n",
        "\n",
        "with open(input_file, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "random.shuffle(lines)\n",
        "\n",
        "split_index = int(0.9 * len(lines))\n",
        "train_lines = lines[:split_index]\n",
        "valid_lines = lines[split_index:]\n",
        "\n",
        "with open(train_file, \"w\") as f:\n",
        "    f.writelines(train_lines)\n",
        "\n",
        "with open(valid_file, \"w\") as f:\n",
        "    f.writelines(valid_lines)\n",
        "\n",
        "print(f\"Training dataset saved to {train_file}\")\n",
        "print(f\"Validation dataset saved to {valid_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LdlB85_CENj9"
      },
      "outputs": [],
      "source": [
        "# Upload a training dataset\n",
        "training_dataset = client.files.create(\n",
        "    file=open(train_file, \"rb\"), # Specify the dataset name\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "# Upload a validation dataset\n",
        "validation_dataset = client.files.create(\n",
        "    file=open(valid_file, \"rb\"), # Specify the dataset name\n",
        "    purpose=\"fine-tune\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlthu1qHGEYS"
      },
      "source": [
        "## Create Fine-Tuning Job\n",
        "Specify the model and fine-tuning parameters, including number of epochs and LoRA adaptation.\n",
        "\n",
        "If you want to add more Parameters, Check your [Nebius Docs](https://docs.nebius.com/studio/fine-tuning/how-to-fine-tune#instructions) for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb_api_key = os.environ.get(\"WANDB_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4viVeKyTESWm"
      },
      "outputs": [],
      "source": [
        "job_request = {\n",
        "    \"model\": \"meta-llama/Llama-3.1-8B-Instruct\", # Choose the model\n",
        "    \"training_file\": training_dataset.id,\n",
        "    \"validation_file\": validation_dataset.id,\n",
        "    \"hyperparameters\": {\n",
        "        \"n_epochs\": 3, # Number of epochs for training\n",
        "        \"batch_size\": 4,\n",
        "        \"learning_rate\": 0.0003,\n",
        "        \"lora\": True,  # Enable LoRA for fine-tuning efficiency,\n",
        "        \"lora_r\": 16,\n",
        "        \"lora_alpha\": 32,\n",
        "        \"lora_dropout\": 0.1\n",
        "    },\n",
        "    \"seed\": 42,\n",
        "    \"integrations\": [\n",
        "        {\n",
        "         \"type\": \"wandb\",\n",
        "         \"wandb\": {\n",
        "            \"api_key\": wandb_api_key,\n",
        "            \"project\": \"llama-ft-project\"\n",
        "         }\n",
        "      }\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Create and run the fine-tuning job\n",
        "job = client.fine_tuning.jobs.create(**job_request)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19TxkUtADrFL"
      },
      "source": [
        "## Monitor Fine-Tuning Status\n",
        "Check the job status periodically to determine whether it is running, completed, or failed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN-iOsyfEYXG"
      },
      "outputs": [],
      "source": [
        "# Create and run the fine-tuning job\n",
        "job = client.fine_tuning.jobs.create(**job_request)\n",
        "\n",
        "# Make sure that the job has been finished or cancelled\n",
        "active_statuses = [\"validating_files\", \"queued\", \"running\"]\n",
        "while job.status in active_statuses:\n",
        "    time.sleep(15)\n",
        "    job = client.fine_tuning.jobs.retrieve(job.id)\n",
        "    print(\"current status is\", job.status)\n",
        "\n",
        "print(\"Job ID:\", job.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4mnjsgLGe8b"
      },
      "source": [
        "## Retrieve Fine-Tuned Model Checkpoints\n",
        "If the fine-tuning job succeeds, retrieve the trained model checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKdILTkfEajs"
      },
      "outputs": [],
      "source": [
        "if job.status == \"succeeded\":\n",
        "    # Check the job events\n",
        "    events = client.fine_tuning.jobs.list_events(job.id)\n",
        "    print(events)\n",
        "\n",
        "    for checkpoint in client.fine_tuning.jobs.checkpoints.list(job.id).data:\n",
        "        print(\"Checkpoint ID:\", checkpoint.id)\n",
        "\n",
        "        # Create a directory for every checkpoint\n",
        "        os.makedirs(checkpoint.id, exist_ok=True)\n",
        "\n",
        "        for model_file_id in checkpoint.result_files:\n",
        "            # Get the name of a model file\n",
        "            filename = client.files.retrieve(model_file_id).filename\n",
        "\n",
        "            # Retrieve the contents of the file\n",
        "            file_content = client.files.content(model_file_id)\n",
        "\n",
        "            # Save the contents into a local file\n",
        "            file_content.write_to_file(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the fine-tuned model\n",
        "\n",
        "After fine-tuning, I have deployed the model on Nebius AI Studio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chat with the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Understanding Agentic AI\n",
              "\n",
              "#### Key Characteristics of Agentic AI\n",
              "\n",
              "- **Definition**: Agentic AI refers to a type of AI system that possesses characteristics of autonomy, self-awareness, and social intelligence, enabling it to interact with humans and other agents in a more human-like and adaptive manner.\n",
              "\n",
              "- **Core Components**:\n",
              "  - Perception and understanding\n",
              "  - Self-awareness and meta-cognition\n",
              "  - Adaptive behavior and learning\n",
              "  - Social interaction and communication\n",
              "\n",
              "#### Key Characteristics of Agentic AI Systems\n",
              "\n",
              "- **Autonomous Decision-Making**:\n",
              "  - Ability to make decisions without human intervention\n",
              "  - Self-directed learning and adaptation\n",
              "  - Real-time response generation\n",
              "\n",
              "- **Social Intelligence**:\n",
              "  - Understanding human emotions and behavior\n",
              "  - Developing social relationships\n",
              "  - Cultural adaptation capabilities\n",
              "\n",
              "#### Implementation Approaches\n",
              "\n",
              "- **Architecture**:\n",
              "  - Modular design with multiple components\n",
              "  - Neural network structure for learning\n",
              "  - Hybrid approaches combining symbolic and connectionist AI\n",
              "\n",
              "- **Training Methods**:\n",
              "  - Reinforcement learning for behavior\n",
              "  - Imitation learning from human demonstrations\n",
              "  - Multi-task learning for diverse capabilities\n",
              "\n",
              "#### Applications and Examples\n",
              "\n",
              "- **Virtual Assistants**: Siri, Alexa, Google Assistant\n",
              "- **Game AI**: AI opponents in strategy games\n",
              "- **Customer Service AI**: Chatbots with human-like conversation\n",
              "\n",
              "#### Challenges and Considerations\n",
              "\n",
              "- **Ethical Implications**:\n",
              "  - Transparency and accountability\n",
              "  - Bias and fairness\n",
              "  - Privacy and consent\n",
              "\n",
              "- **Technical Challenges**:\n",
              "  - Scalability and reliability\n",
              "  - Communication efficiency\n",
              "  - System safety and security\n",
              "\n",
              "## Conclusion\n",
              "Agentic AI represents a significant advancement in AI capabilities, combining human-like intelligence with autonomous capabilities. Its development requires careful consideration of multiple technical, ethical, and practical aspects."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\")\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=os.environ.get(\"MODEL_ID\"),\n",
        "    messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"You are an expert in Generative AI. In particular, you have strong understanding of four subtopics: Responsible AI, Agentic AI, Prompt Engineering and Foundation models.\\nYou are given a fact-based and exam-style question about one of these subtopics. Write a response that is the best possible answer to the given question. The answer MUST have:\\n- High accuracy: factually accurate, well-researched and precise.\\n- Maximum comprehensiveness: long, nuanced, and detailed.\\n- Diverse viewpoints, key points and perspectives: Include multiple key aspects and perspectives with the discussions on each.\\n- Well-structured output: Use Markdown for clear formatting and better readability.\\n- No hallucination: Stick to verifiable facts. Do not make up any information.\"\n",
        "        },\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": \"What is Agentic AI?\"\n",
        "        }\n",
        "    ],\n",
        "    top_p=0.5,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "ft_model_generation = response.choices[0].message.content\n",
        "\n",
        "display(Markdown(ft_model_generation))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llama_ft",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
