{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCJAFNEzF4Vl"
      },
      "source": [
        "## Initialize OpenAI Client\n",
        "Set up the OpenAI client with Nebius AI's API endpoint and your API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9lE90uSDllW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv-WrbiMFtuL"
      },
      "source": [
        "## Upload Training and Validation Datasets\n",
        "Nebius AI requires datasets in `.jsonl` format. Upload your training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdlB85_CENj9"
      },
      "outputs": [],
      "source": [
        "# Upload a training dataset\n",
        "training_dataset = client.files.create(\n",
        "    file=open(\"<dataset_name>.jsonl\", \"rb\"), # Specify the dataset name\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "# Upload a validation dataset\n",
        "validation_dataset = client.files.create(\n",
        "    file=open(\"<dataset_name>.jsonl\", \"rb\"), # Specify the dataset name\n",
        "    purpose=\"fine-tune\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlthu1qHGEYS"
      },
      "source": [
        "## Create Fine-Tuning Job\n",
        "Specify the model and fine-tuning parameters, including number of epochs and LoRA adaptation.\n",
        "\n",
        "If you want to add more Parameters, Check your [Nebius Docs](https://docs.nebius.com/studio/fine-tuning/how-to-fine-tune#instructions) for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4viVeKyTESWm"
      },
      "outputs": [],
      "source": [
        "job_request = {\n",
        "    \"model\": \"meta-llama/Llama-3.1-8B-Instruct\", # Choose the model\n",
        "    \"training_file\": training_dataset.id,\n",
        "    \"validation_file\": validation_dataset.id,\n",
        "    \"hyperparameters\": {\n",
        "        \"n_epochs\": 3, # Number of epochs for training\n",
        "        \"lora\": True,  # Enable LoRA for fine-tuning efficiency\n",
        "    },\n",
        "    \"integrations\": [],\n",
        "}\n",
        "\n",
        "# Create and run the fine-tuning job\n",
        "job = client.fine_tuning.jobs.create(**job_request)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19TxkUtADrFL"
      },
      "source": [
        "## Monitor Fine-Tuning Status\n",
        "Check the job status periodically to determine whether it is running, completed, or failed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN-iOsyfEYXG"
      },
      "outputs": [],
      "source": [
        "# Create and run the fine-tuning job\n",
        "job = client.fine_tuning.jobs.create(**job_request)\n",
        "\n",
        "# Make sure that the job has been finished or cancelled\n",
        "active_statuses = [\"validating_files\", \"queued\", \"running\"]\n",
        "while job.status in active_statuses:\n",
        "    time.sleep(15)\n",
        "    job = client.fine_tuning.jobs.retrieve(job.id)\n",
        "    print(\"current status is\", job.status)\n",
        "\n",
        "print(\"Job ID:\", job.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4mnjsgLGe8b"
      },
      "source": [
        "## Retrieve Fine-Tuned Model Checkpoints\n",
        "If the fine-tuning job succeeds, retrieve the trained model checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKdILTkfEajs"
      },
      "outputs": [],
      "source": [
        "if job.status == \"succeeded\":\n",
        "    # Check the job events\n",
        "    events = client.fine_tuning.jobs.list_events(job.id)\n",
        "    print(events)\n",
        "\n",
        "    for checkpoint in client.fine_tuning.jobs.checkpoints.list(job.id).data:\n",
        "        print(\"Checkpoint ID:\", checkpoint.id)\n",
        "\n",
        "        # Create a directory for every checkpoint\n",
        "        os.makedirs(checkpoint.id, exist_ok=True)\n",
        "\n",
        "        for model_file_id in checkpoint.result_files:\n",
        "            # Get the name of a model file\n",
        "            filename = client.files.retrieve(model_file_id).filename\n",
        "\n",
        "            # Retrieve the contents of the file\n",
        "            file_content = client.files.content(model_file_id)\n",
        "\n",
        "            # Save the contents into a local file\n",
        "            file_content.write_to_file(filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
